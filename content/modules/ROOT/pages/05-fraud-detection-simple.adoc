= Fraud-detection with encrypted data

This example demonstrates a typical Confidential Containers (CoCo) deployment using a fraud-detection application. The primary goal is to show how CoCo protects **data in use**, even when the application code itself is public.

We will run a model to perform offline credit-card fraud detection, based on the following scenario.

== Protecting Data, Not Code

This deployment operates on two key assumptions:

* The Model is Public: The fraud-detection model itself is not secret. It was pre-trained on public data and does not require protection.
* The Data is Private: The credit card datasets contain sensitive customer information and must be protected. This data has been securely collected and encrypted before entering our untrusted cluster.

A similar demonstration was shown at Red Hat Summit 2025, which used Confidential Virtual Machines (CVMs) instead of CoCo. You can learn more from this https://www.redhat.com/en/blog/rhel-confidential-virtual-machines-protect-ai-workloads-microsoft-azure[blogpost, window=blank] and https://www.youtube.com/watch?v=ty21OQhwgvk[video, window=blank].

== Assumptions

In this demo we are not going to show the steps done in the secure environment, to simplify the user experience and not confuse the secure env with the untrusted cluster.

In the secure env we:

* Generate, encrypt and upload the credit cards dataset to the Azure blob storage. In this workshop, it's a publicly accessible blob containing only the encrypted dataset.
* Install and configure Trustee with the key used in the previous point. In this workshop, Trustee is running in the same untrusted cluster but it shouldn't.

These two steps above are already prepared for you, no need to do anything at this point.

== The Confidential Workflow

The entire process relies on remote attestation to securely release the decryption key to the running container. In this demo, we will run the whole workflow.

. The fraud-detection container starts.
. One of the attached volumes in this pod is a sealed secret.
. CoCo internal components read which secret it is actually referring to, and begin attestation to get its content.
.. Attestation starts by first having the confidential container to generate a report that shows it is a genuine CoCo running on a secure, trusted platform.
.. The CoCo then sends this report to Trustee. Only after Trustee verifies that this report is genuine and correct, it can confirm that the container is secure by releasing the requested secret.
. The container downloads the public model.
. Then, it tries to pull the encrypted dataset.
.. The Azure SAS (connection string in a real example) required to access the blob has been loaded as sealed secret in the CoCo pod. If everything went well, it should be available in a volume defined in the podspec.
. Once the blob is accessed, the decryption key is not present in the container; it is held remotely by Trustee too.
.. The key was already added in Trustee xref:02-configure-trustee.adoc#trustee-key[when adding the secrets], or was done automatically by the install script. For this demo, Trustee runs in the same cluster, but in production, it would be in a separate, secure domain.
.. To get the decryption key, the same attestation process done by the sealed secret is performed. This time is just triggered manually by the application.
. The container uses the received key to decrypt the credit card datasets in memory.
. The (now-decrypted) private data is fed into the public model for processing, all within the protected container.

== CoCo-specific implementation steps

The main goal here is to show how much work is actually needed to convert the plain application to securely run with CoCo.

There are three (plus one optional) main changes added to the podspec:

. `runtimeClassName: kata-remote` in the podspec. This is just a single line to enable CoCo for this pod.

. Sealed secrets. Such secrets are added to the podspec as normal secrets, but as we saw xref:02-configure-trustee.adoc#trustee-key[before] such secrets contain a reference to the actual secret provided by Trustee.

. Persistent storage. For CoCo in public cloud using peer-pods, since the pod VM is external to the worker node and PVCs are actually mounted on the worker node, there are no proper and maintainable mechanisms to mount the PVC in the pod VM instead of on the worker node and secure it from the cluster. Itâ€™s left to the application to directly mount the storage and use client side encryption/decryption for the storage.
.. In this example, we will replace the PVCs with podvm storage, meaning the CVM encrypted disk will be used to store data. However, once the pod terminates, the data will be lost too.

. Optional: application-side attestation. The application itself can trigger attestation, by simply querying `localhost`. This of course requires modification in the application itself, but it's not mandatory. Trustee resources can be obtained either via sealed secret, or by providing sidecars that do this, leaving the main application pristine.
.. In this example, we are adding application-side attestation just to show another way to fetch a secret.

== Deploy the notebook

Let's create a notebook and run it as CoCo.

This notebook specifically uses python sdk to download the encrypted data from Azure for two reasons:

* Closely align with regular interactive AI workflows which uses python SDKs to download data from s3, azure, minio etc.
* Provides an example of programmatic storage access for AI workloads when using the peer-pods approach.

Before running this notebook, ensure that `ROOT_VOLUME_SIZE` in the xref:02-configure-osc.adoc#pp-cm[peer-pods configmap] is set at least to `20` GB, as the steps in the guide will install a lot of python packages. If you modify that value, remember as always to to xref:02-configure-osc.adoc##pp-restart[restart the OSC deployment]!

There are two ways to deploy the notebook:

* Via a xref:05-fraud-detection-simple.adoc#fd-oai[Openshift AI (OAI) workbench]: everything is handled by Openshift AI. A `Notebook` object is created, and OAI takes care of deploying it and exposing it for the user. In such way, we integrate CoCo with Openshift AI traditional workbenches, that take care of most of the work.
* Via a xref:05-fraud-detection-simple.adoc#fd-plain[plain Jupyter notebook]: a simple custom pod, with networking handled by a custom service and route. This is the simplest and fastest way to deploy.

[#fd-oai]
=== Openshift AI workbench

==== Prerequisites

First of all, we need to make sure we can install Openshift AI. The main requirement for OAI is to have big enough worker nodes, as they have to run OAI, OSC and Trustee.

[tabs]
====
RHDP Workshop::
+
If you have deployed this workshop with the RHDP catalog, you can choose to have worker nodes as big as `Standard_D8s_v5`. This should be enough. If you haven't picked big enough nodes, there is no problem, as the script below takes care of increasing the worker node size automatically.
+
[source,sh,role=execute]
----
curl -L https://raw.githubusercontent.com/confidential-devhub/workshop-on-ARO-showroom/refs/heads/main/helpers/increase-worker-size.sh -o increase-worker-size.sh

chmod +x increase-worker-size.sh

./increase-worker-size.sh
----

ARO/Azure standard deployments::
+
You need to manually upgrade the worker node or deploy a new cluster with big enough workers. Alternatively you can try to add more worker nodes.
====

==== Install OAI

In order to simplify the installation of OAI and since it's not the focus of this workshop, we will provide a script to automatically handle that:

[source,sh,role=execute]
----
curl -L https://raw.githubusercontent.com/confidential-devhub/workshop-on-ARO-showroom/refs/heads/main/helpers/install-oai.sh -o install-oai.sh

chmod +x install-oai.sh

./install-oai.sh
----

Once completed, you will receive a link to access the RHOAI dashboard and also the notebook itself directly.

Now you can xref:05-fraud-detection-simple.adoc#fd-run[go through the notebook].

[#fd-plain]
=== Plain Jupyter notebook

If you open the https://raw.githubusercontent.com/confidential-devhub/workshop-on-ARO-showroom/refs/heads/main/helpers/fraud-encrypted-datasets/notebook.yaml[yaml code, window=blank] for the plain jupyter notebook, you will notice once again the only difference with a normal deployment is `runtimeClassName: kata-remote`.

[source,sh,role=execute]
----
oc apply -f https://raw.githubusercontent.com/confidential-devhub/workshop-on-ARO-showroom/refs/heads/main/helpers/fraud-encrypted-datasets/notebook.yaml
----

Switch to the newly created `fraud-detection` namespace.

[source,sh,role=execute]
----
oc project fraud-detection
----

Wait that the pod is created.
[source,sh,role=execute]
----
watch oc get pods/fraud-encrypted-datasets
----
The pod is ready when the `STATUS` is in `Running`.

The jupyter notebook will be available at the following URL and the login password is `aro_workshop123`:
[source,sh,role=execute]
----
FD_ROUTE=$(oc get route fraud-encrypted-datasets-route -n fraud-detection -o jsonpath='{.spec.host}')
echo ""

echo "Click on the following URL to open the notebook in a new tab:"
echo "https://${FD_ROUTE}"
----

[#fd-run]
== Run the notebook

Starting from `fraud-detection/1_download_data.ipynb`, go through the various notebooks. Specifically:

* `fraud-detection/1_download_data.ipynb`: download encrypted datasets
* `fraud-detection/2_decrypt_data.ipynb`: fetch key through attestation and decrypt the datasets
* `fraud-detection/3_run_model.ipynb`: run the model
* `fraud-detection/4_cleanup.ipynb`: clean everything to restart the demo

== Considerations

Note for a second how a secret like `/sealed/azure-value/azure-sas` can be read and used in the jupyter notebook, but if you try to `oc exec` and read it, it won't work.

The difference is that the notebook is running **within** the container, whereas `oc exec` is executed from outside. This shows exactly the CoCo threat model: an application/developer *inside* the CoCo pod is obviously allowed to read the secrets granted. However, a cluster/infra/platform admin is not trusted, therefore there is no way for him/her to access this data.

== Delete the notebook
The pod created in this example section are no different from any other pod, therefore it can be destroyed just as the others (via command line, web ui, OAI etc.). Behind the scenes, the operator will make sure that the created VM will also be completely deallocated.
