= Fraud-detection with encrypted data

pass:[<span style="color: red;"><b>PERSONA:</b></span>] Application developer

This example demonstrates a typical Confidential Containers (CoCo) deployment using a fraud-detection application. The primary goal is to show how CoCo protects **data in use**, even when the application code itself is public.

We will run a model to perform offline credit-card fraud detection, based on the following scenario.

== Protecting Data, Not Code

This deployment operates on two key assumptions:

* The Model is Public: The fraud-detection model itself is not secret. It was pre-trained on public data and does not require protection.
* The Data is Private: The credit card datasets contain sensitive customer information and must be protected. This data has been securely collected and encrypted before entering our untrusted cluster.

A similar demonstration was shown at Red Hat Summit 2025, which used Confidential Virtual Machines (CVMs) instead of CoCo. You can learn more from this https://www.redhat.com/en/blog/rhel-confidential-virtual-machines-protect-ai-workloads-microsoft-azure[blogpost, window=blank] and https://www.youtube.com/watch?v=ty21OQhwgvk[video, window=blank].

== Assumptions

In this demo we are not going to show the steps done in the secure environment, to simplify the user experience and not confuse the secure env with the untrusted cluster.

In the secure env we:

* Generate, encrypt and upload the credit cards dataset to the Azure blob storage. In this workshop, it's a publicly accessible blob containing only the encrypted dataset.
* Install and configure Trustee with the key used in the previous point. In this workshop, Trustee is running in the same untrusted cluster but it shouldn't.

These two steps above are already prepared for you, no need to do anything at this point.

== The Confidential Workflow

The entire process relies on remote attestation to securely release the decryption key to the running container. In this demo, we will run the whole workflow.

. The fraud-detection container starts.
. Two of the attached volumes in this pod are sealed secret (azure credentials and decryption key).
. CoCo internal components find the sealed secrets, and begin attestation to get their content.
.. Attestation starts by first having the confidential container to generate a report that shows it is a genuine CoCo running on a secure, trusted platform.
.. The CoCo then sends this report to Trustee. Only after Trustee verifies that this report is genuine and correct, it can confirm that the container is secure by releasing the requested secret.
.. The secret is then inserted in the corresponding sealed secret, which acts as normal volume mount.
. The container downloads the public model.
. Then, it tries to pull the encrypted dataset. The Azure credentials are not available in the container; they are held remotely by Trustee.
.. The Azure SAS (connection string in a real example) required to access the blob has been loaded as sealed secret in the CoCo pod. If everything went well, it should be available in a volume defined in the podspec.
. Once the blob is accessed, the decryption key is not present in the container; it is held remotely by Trustee too.
.. The key required to decrypt the dataset has been loaded as sealed secret in the CoCo pod. If everything went well, it should be available in a volume defined in the podspec.
.. In addition, in the jupyter notebook it is also possible to try lazy attestation to fetch the key manually.
. The container uses the received key to decrypt the credit card datasets in memory.
. The (now-decrypted) private data is fed into the public model for processing, all within the protected container.

== CoCo-specific implementation steps

The main goal here is to show how much work is actually needed to convert the plain application to securely run with CoCo.

There are three main changes added to the podspec:

. `runtimeClassName: kata-remote` in the podspec. This is just a single line to enable CoCo for this pod.

. Sealed secrets. Such secrets are added to the podspec as normal secrets, but as we saw xref:dev-add-secrets.adoc#sealed-secrets[before] such secrets contain a reference to the actual secret provided by Trustee.

. Persistent storage. For CoCo in public cloud using peer-pods, since the pod VM is external to the worker node and PVCs are actually mounted on the worker node, there are no proper and maintainable mechanisms to mount the PVC in the pod VM instead of on the worker node and secure it from the cluster. Itâ€™s left to the application to directly mount the storage and use client side encryption/decryption for the storage.
.. In this example, we will replace the PVCs with podvm storage, meaning the CVM encrypted disk will be used to store data. However, once the pod terminates, the data will be lost too.

== Add the application secrets into Trustee

Let's add the application secrets (decryption key and azure credentials) into the Trustee. Here we are in the **trusted** cluster.

[source,sh,role=execute]
----
### dataset decryption key - application requires it
curl -L https://people.redhat.com/eesposit/fd-workshop-key.bin -o fd.bin
FD_SECRET_NAME=fraud-dataset-key
oc create secret generic $FD_SECRET_NAME \
  --from-file dataset_key=fd.bin \
  -n trustee-operator-system
rm -rf fd.bin

### Azure SAS - sealed secret
AZURE_SAS_SECRET_NAME=fraud-azure-sas

oc create secret generic $AZURE_SAS_SECRET_NAME \
  --from-literal azure-sas="sp=r&st=2025-10-27T15:42:27Z&se=2028-10-27T22:57:27Z&spr=https&sv=2024-11-04&sr=b&sig=vjaRotd7de%2B3QwlzHVaHF2GVyehw1xb3fFiXe9E7YOI%3D" \
  -n trustee-operator-system
----

And then instruct Trustee to load that secret into its deployment, by updating the xref:configure-trustee.adoc#trustee-kbsconfig[KbsConfig] and xref:configure-trustee.adoc#trustee-restart[restarting the Trustee deployment].

[source,sh,role=execute]
----
echo "Default Kbsconfig - kbsSecretResources:"
oc get kbsconfig trusteeconfig-kbs-config -n trustee-operator-system -o json \
  | jq '.spec.kbsSecretResources'

echo ""

oc patch kbsconfig trusteeconfig-kbs-config \
  -n trustee-operator-system \
  --type=json \
  -p="[
    {\"op\": \"add\", \"path\": \"/spec/kbsSecretResources/-\", \"value\": \"$FD_SECRET_NAME\"},
    {\"op\": \"add\", \"path\": \"/spec/kbsSecretResources/-\", \"value\": \"$AZURE_SAS_SECRET_NAME\"},
  ]"

echo ""

echo "Updated Kbsconfig - kbsSecretResources:"
oc get kbsconfig trusteeconfig-kbs-config -n trustee-operator-system -o json \
  | jq '.spec.kbsSecretResources'

oc rollout restart deployment/trustee-deployment -n trustee-operator-system
----

== Create the sealed secret

Let's now create the sealed secret that contains the pointer to the actual secret in trustee. Here we move to the **untrusted** cluster.

[source,sh,role=execute]
----
AZ_SECRET=$(podman run -it quay.io/confidential-devhub/coco-tools:0.3.0 /tools/secret seal vault --resource-uri kbs:///default/${AZURE_SAS_SECRET_NAME}/azure-sas --provider kbs | grep -v "Warning")

KEY_SECRET=$(podman run -it quay.io/confidential-devhub/coco-tools:0.3.0 /tools/secret seal vault --resource-uri kbs:///default/${FD_SECRET_NAME}/dataset_key --provider kbs | grep -v "Warning")

# namespace here is fraud-detection!
oc create namespace fraud-detection
oc create secret generic sealed-azure-sas --from-literal=azure-sas=$AZ_SECRET -n fraud-detection
oc create secret generic sealed-dataset-key --from-literal=key=$KEY_SECRET -n fraud-detection
----

== Deploy the notebook

Let's create a notebook and run it as CoCo.

This notebook specifically uses python sdk to download the encrypted data from Azure for two reasons:

* Closely align with regular interactive AI workflows which uses python SDKs to download data from s3, azure, minio etc.
* Provides an example of programmatic storage access for AI workloads when using the peer-pods approach.

Before running this notebook, ensure that `ROOT_VOLUME_SIZE` in the xref:configure-osc.adoc#pp-cm[peer-pods configmap] is set at least to `20` GB, as the steps in the guide will install a lot of python packages. If you modify that value, remember as always to to xref:configure-osc.adoc##pp-restart[restart the OSC deployment]!

There are two ways to deploy the notebook:

* Via a xref:fraud-detection.adoc#fd-oai[Openshift AI (OAI) workbench]: everything is handled by Openshift AI. A `Notebook` object is created, and OAI takes care of deploying it and exposing it for the user. In such way, we integrate CoCo with Openshift AI traditional workbenches, that take care of most of the work.
* Via a xref:fraud-detection.adoc#fd-plain[plain Jupyter notebook]: a simple custom pod, with networking handled by a custom service and route. This is the simplest and fastest way to deploy.

[#fd-oai]
=== Openshift AI workbench

==== Prerequisites

First of all, we need to make sure we can install Openshift AI. The main requirement for OAI is to have big enough worker nodes, as they have to run OAI, OSC and Trustee.

[tabs]
====
RHDP Workshop::
+
If you have deployed this workshop with the RHDP catalog, you can choose to have worker nodes as big as `Standard_D8s_v5`. This should be enough. If you haven't picked big enough nodes, there is no problem, as the script below takes care of increasing the worker node size automatically.
+
[source,sh,role=execute]
----
curl -L https://raw.githubusercontent.com/confidential-devhub/workshop-on-ARO-showroom/refs/heads/main/helpers/increase_worker_size.sh -o increase_worker_size.sh

chmod +x increase_worker_size.sh

./increase_worker_size.sh
----

ARO/Azure standard deployments::
+
You need to manually upgrade the worker node or deploy a new cluster with big enough workers. Alternatively you can try to add more worker nodes.
====

==== Install OAI

In order to simplify the installation of OAI and since it's not the focus of this workshop, we will provide a script to automatically handle that:

[source,sh,role=execute]
----
curl -L https://raw.githubusercontent.com/confidential-devhub/workshop-on-ARO-showroom/refs/heads/main/helpers/install-oai.sh -o install-oai.sh

chmod +x install-oai.sh

./install-oai.sh
----

Once completed, you will receive a link to access the RHOAI dashboard and also the notebook itself directly.

Now you can xref:fraud-detection.adoc#fd-run[go through the notebook].

[#fd-plain]
=== Plain Jupyter notebook

If you open the https://raw.githubusercontent.com/confidential-devhub/workshop-on-ARO-showroom/refs/heads/main/helpers/fraud-encrypted-datasets/notebook.yaml[yaml code, window=blank] for the plain jupyter notebook, you will notice once again the only difference with a normal deployment is `runtimeClassName: kata-remote`.

[source,sh,role=execute]
----
oc apply -f https://raw.githubusercontent.com/confidential-devhub/workshop-on-ARO-showroom/refs/heads/main/helpers/fraud-encrypted-datasets/notebook.yaml
----

Switch to the newly created `fraud-detection` namespace.

[source,sh,role=execute]
----
oc project fraud-detection
----

Wait that the pod is created.
[source,sh,role=execute]
----
watch oc get pods/fraud-encrypted-datasets
----
The pod is ready when the `STATUS` is in `Running`.

The jupyter notebook will be available at the following URL and the login password is `aro_workshop123`:
[source,sh,role=execute]
----
FD_ROUTE=$(oc get route fraud-encrypted-datasets-route -n fraud-detection -o jsonpath='{.spec.host}')
echo ""

echo "Click on the following URL to open the notebook in a new tab:"
echo "https://${FD_ROUTE}"
----

[#fd-run]
== Run the notebook

Starting from `fraud-detection/1_download_data.ipynb`, go through the various notebooks. Specifically:

* `fraud-detection/1_download_data.ipynb`: download encrypted datasets
* `fraud-detection/2_decrypt_data.ipynb`: decrypt the datasets
* `fraud-detection/3_run_model.ipynb`: run the model
* `fraud-detection/4_cleanup.ipynb`: clean everything to restart the demo

== Considerations

Note for a second how a secret like `/sealed/azure-value/azure-sas` can be read and used in the jupyter notebook, but if you try to `oc exec` and read it, it won't work.

The difference is that the notebook is running **within** the container, whereas `oc exec` is executed from outside. This shows exactly the CoCo threat model: an application/developer *inside* the CoCo pod is obviously allowed to read the secrets granted. However, a cluster/infra/platform admin is not trusted, therefore there is no way for him/her to access this data.

== Delete the notebook
The pod created in this example section are no different from any other pod, therefore they can be destroyed just as the others (via command line, web ui, OAI etc.). Behind the scenes, the operator will make sure that the created VM will also be completely deallocated.
